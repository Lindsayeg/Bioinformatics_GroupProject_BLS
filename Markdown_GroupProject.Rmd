---
title: "BioInfo_GroupProject"
author: "Lindsay Serene, Bhavana Palakurthi, and Shane Davitt"
date: "12/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###**Aim 1: Identify the genes encoded by 6 differnetially expressed transcripts in *uniquetrancripts.fasta* using BLAST.**

1. Upload *uniquetrancripts.fasta* file to *https://blast.ncbi.nlm.nih.gov/* and BLAST the file with the following permutations:
    + Database = *Nucelotide collection (nr/nt)*
    + Optimization = *Highly similar sequences (Megablast)*
    + Click **BLAST** to start the search.
2. When the searches were complete, we used the **Results for:** drop down menu to toggle between transcripts and have a look at each one.
3. Under the *Descriptions* heading, a copy of each hits table was saved, for each trancript, by clicking on *Download -> Hit Table (CSV)*. These files were later uploaded to the group repositiory.
4. In Unix, a single table was made containing the top hit from each transcript as below:

```{Unix Code}
for file in *.csv
do
cat $file | head -1 $file >> TopHits2.csv 
done
```

5. In the Protein database of NCBI, we then searched the name of the protein associated with the top hit of each transcript (for each of the six transcripts in uniquetranscripts.fasta) for its amino acid sequence.
6. Form this output, 10-20 sequences from mice (*Mus musculus*) and other closely related organisms were chosen.
7. One Fasta file of 10-20 sequences was download for the protein identified from each transcript (6 in total) by clicking: send to -> *file -> FASTA -> Create File*.

###**Aim 2: Translate the 4 provided files of "RNAseq data" into proteins.

Here we began by setting our working directory, reading in our four files to be translated (Control1, Control2, Obese1, and Obese2), and loading any necessary packages.

```{r, message=FALSE, warning=FALSE}
#Set working directory and read each of the original neucleotide fasta files.
setwd("~/Desktop/data-shell/BioInfo_GroupProject/Bioinformatics_GroupProject_BLS/Original_Files/")

#Read in fasta file, each line becomes an item in a vector
Codon_Map=scan("codonmap.txt",what=character(),sep="\n")
Control1=scan("control1.fasta",what=character(),sep="\n")
Control2=scan("control2.fasta",what=character(),sep="\n")
Obese1=scan("obese1.fasta",what=character(),sep="\n")
Obese2=scan("obese2.fasta",what=character(),sep="\n")

#Load package
library('stringr')
library('devtools')
library('seqinr')
```

As we were told our genes of interest were all in the first open reading frame, our first main challenge of Aim 2 was to identify and isolate the gene of interest, by determining the correct start and stop codons and then extracting the entire sequence from ATG to TAA/TGA/TAG.

```{r}
#Create a vector one half the length of Control1, Control2, Obese1, and Obese2.
Control1_ORF = character(length(Control1)/2)
Control2_ORF = character(length(Control2)/2)
Obese1_ORF = character(length(Obese2)/2)
Obese2_ORF = character(length(Obese2)/2)

###Determine the ORF of each sequence file using a for loop.
for (Line in 1:length(Control1)){
  #Operate only on lines that do not include >, skips header lines.
  #Note that str_detect returns a logical T/F.
  if (!str_detect(Control1[Line],">")){
    #Find the ORF in each sequence line and write to a new file.
    #Search for the start codon (ATG) in each line of Control1 (with grepexpr) and       assign it a new variable called atg_positions.
    atg_positions <- gregexpr('ATG', Control1[Line])[[1]]
    #Determine which codons are in the first reading frame (where atg_position is        divisible by 3), and assign the position of the first to a new variable called      start_codon_position.
    start_codon_position <- min(atg_positions[atg_positions%%3==1])
    #Extract sequences from each line of Control 1 from the first start codon            position and place into a new variable called ORF_Temp.
    ORF_temp <- substring(Control1[Line], start_codon_position)
    #Repeat this process for the stop codon, by first searching for each of the          three stop codons in ORF_Temp.
    end_positions <- gregexpr("(TAA)|(TAG)|(TGA)", ORF_temp)[[1]]
    #Determine which stop codons are in the first reading frame (where                   stop_codon_position is divisible by 3), and assign the position of the first to      a new variable called end_positions.
    end_codon_position <- min(end_positions[end_positions%%3==1])
    #Extract the sequence from each line from the start codon in ORF_temp to the         first stop codon and assign it a final varible.
    Control1_ORF[Line/2] = substring(ORF_temp, 1, end_codon_position+2)
  }
}

#Repeat for each file: Control2, Obese1, and Obese2.
#Control2
for (Line in 1:length(Control2)){
  if (!str_detect(Control2[Line],">")){
    atg_positions2 <- gregexpr('ATG', Control2[Line])[[1]]
    start_codon_position2 <- min(atg_positions2[atg_positions2%%3==1])
    ORF_temp2 <- substring(Control2[Line], start_codon_position2)
    end_positions2 <- gregexpr("(TAA)|(TAG)|(TGA)", ORF_temp2)[[1]]
    end_codon_position2 <- min(end_positions2[end_positions2%%3==1])
    Control2_ORF[Line/2] = substring(ORF_temp2, 1, end_codon_position2+2)
  }
}

#Obese1
for (Line in 1:length(Obese1)){
  if (!str_detect(Obese1[Line],">")){
    atg_positions3 <- gregexpr('ATG', Obese1[Line])[[1]]
    start_codon_position3 <- min(atg_positions3[atg_positions3%%3==1])
    ORF_temp3 <- substring(Obese1[Line], start_codon_position3)
    end_positions3 <- gregexpr("(TAA)|(TAG)|(TGA)", ORF_temp3)[[1]]
    end_codon_position3 <- min(end_positions3[end_positions3%%3==1])
    Obese1_ORF[Line/2] = substring(ORF_temp3, 1, end_codon_position3+2)
  }
}

#Obese2
for (Line in 1:length(Obese2)){
  if (!str_detect(Obese2[Line],">")){
    atg_positions4 <- gregexpr('ATG', Obese2[Line])[[1]]
    start_codon_position4 <- min(atg_positions4[atg_positions4%%3==1])
    ORF_temp4 <- substring(Obese2[Line], start_codon_position4)
    end_positions4 <- gregexpr("(TAA)|(TAG)|(TGA)", ORF_temp4)[[1]]
    end_codon_position4 <- min(end_positions4[end_positions4%%3==1])
    Obese2_ORF[Line/2] = substring(ORF_temp4, 1, end_codon_position4+2)
  }
}
```
Alternatively we also have another method to extract open reading frame and translate it. We have them explained below.
```{r, message=FALSE, warning=FALSE}
##Translating RNAseq files into aminoacid sequences
##Using regex and translate function from seqinr 
##
#Assign empty character vectors for file to extract open reading frame into them
match1=character(length(control1)/2)
match2=character(length(control2)/2)
match3=character(length(obese1)/2)
match4=character(length(obese2)/2)
##
##
#Read the nucleotide fasta files control 1&2 and obese 1&2
control1=scan(file = "control1.fasta.txt", what = character(), sep = "\n")
control2=scan(file = "control2.fasta.txt", what = character(), sep = "\n")
obese1=scan(file = "obese1.fasta.txt", what = character(), sep = "\n")
obese2=scan(file = "obese2.fasta.txt", what = character(), sep = "\n")
##
##
#Load stringr/i and seqinr packages
library(stringr)
library(stringi)
library(seqinr)
##
##
##
##
#forloop to extraxt openreading frame of control1 seq file
for (Line in 1:length(control1)){
#Operate only on lines that do not include >, skips header lines
#Note that str_detect returns a logical T/F
if (!str_detect(control1[Line],">")==TRUE){
#Find the ORF in each sequence line
match1[Line/2] = str_match(control1[Line],"([ATCG]{3})*?(ATG([ATCG]{3})+?(TAA|TAG|TGA))")[,3]
#Print the ORF to standard out
print(match1)
  }
}
##
#create an empty vector of length equal to match1 each for tranlated amino acid sequences before and after formating
control1aa=character(length(match1))
control1protein=c(length(match1))
#use translate function to translate nucleotides into aa through a for loop
for(Line in 1:length(match1)){
#translate sequence of each line from the match1 in a loop
  control1aa=(translate(s2c(match1[Line])))
#print the translated sequence to standard out
  print(control1aa)
#format the output by removing quotes from each amino acid
  control1protein[Line]=paste(control1aa, sep="", collapse="")
  print(control1protein)
#write the sequence of aminoacids in a fasta file format
  write.fasta(sequences = as.list(control1protein), names = rep("control1", times=length(control1protein)),file.out = "control1protein.fasta")
}
##
##
##Repeat the same for all the original files(control2,obese1,and obese2)
##
##
#forloop for control2 seq file orf extract
for (Line in 1:length(control2)){
#Operate only on lines that do not include >, skips header lines
#Note that str_detect returns a logical T/F
if (!str_detect(control2[Line],">")==TRUE){
#Find the ORF in each sequence line
match2[Line/2] = str_match(control2[Line],"([ATCG]{3})*?(ATG([ATCG]{3})+?(TAA|TAG|TGA))")[,3]
#Print the ORF to standard out
print(match2)
}
}
##
#create an empty vector of length equal to match2 each for storing translated aminoacid before and after formating
control2aa=character(length(match2))
control2protein=c(length(match2))
#use translate function to translate nucleotides into aa through a for loop
for(Line in 1:length(match2)){
#translate sequence of each line from the match1 in a loop
  control2aa=(translate(s2c(match2[Line])))
#print the translated sequence to standard out
  print(control2aa)
#format the output by removing quotes from each amino acid
  control2protein[Line]=paste(control2aa, sep="", collapse="")
#print the formated translated sequence to standard out
  print(control2protein)
#write the sequence of aminoacids in a fasta file format
  write.fasta(sequences = as.list(control2protein), names = rep("control2", times=length(control2protein)),file.out = "control2protein.fasta")
}
##
##
#forloop for obese1 seq file orf extract
for (Line in 1:length(obese1)){
  #Operate only on lines that do not include >, skips header lines
  #Note that str_detect returns a logical T/F
  if (!str_detect(obese1[Line],">")==TRUE){
    #Find the ORF in each sequence line
    match3[Line/2] = str_match(obese1[Line],"([ATCG]{3})*?(ATG([ATCG]{3})+?(TAA|TAG|TGA))")[,3]
    #Print the ORF to standard out
    print(match3)
  }
}
##
##
##
#create an empty vector of length equal to match3 each 
#for storing translated aminoacid before and after formating
obese1aa=character(length(match3))
obese1protein=c(length(match3))
##
##
#use translate function to translate nucleotides into aa through a for loop
for(Line in 1:length(match3)){
#translate sequence of each line from the match1 in a loop
obese1aa=(translate(s2c(match3[Line])))
#print the translated sequence to standard out
print(obese1aa)
#format the output by removing quotes from each amino acid
obese1protein[Line]=paste(obese1aa, sep="", collapse="")
#print the formated translated sequence to standard out
print(obese1protein)
#write the sequence of aminoacids in a fasta file format
  write.fasta(sequences = as.list(obese1protein), names = rep("obese1", times=length(obese1protein)),file.out = "obese1protein.fasta")
  }
##
##
##
#forloop for obese2 seq file orf extract
for (Line in 1:length(obese2)){
#Operate only on lines that do not include >, skips header lines
#Note that str_detect returns a logical T/F
if (!str_detect(obese2[Line],">")==TRUE){
#Find the ORF in each sequence line
match4[Line/2] = str_match(obese2[Line],"([ATCG]{3})*?(ATG([ATCG]{3})+?(TAA|TAG|TGA))")[,3]
    #Print the ORF to standard out
    print(match4)
}
  }
##
##
#create an empty vector of length equal to match4 each 
#for storing translated aminoacid before and after formating
obese2aa=character(length(match4))
obese2protein=c(length(match4))
##
##
#use translate function of seqinr package to translate nucleotides into aa
for(Line in 1:length(match4)){
#translate sequence of each line from the match1 in a loop
obese2aa=(translate(s2c(match4[Line])))
#print the translated sequence to standard out
print(obese2aa)
#format the output by removing quotes from each amino acid
obese2protein[Line]=paste(obese2aa, sep="", collapse="")
#print the formated translated sequence to standard out
print(obese2protein)
#write the sequence of aminoacids in a fasta file format
write.fasta(sequences = as.list(obese2protein), names = rep("obese2", times=length(obese2protein)),file.out = "obese2protein.fasta")
  }
```
Having identified the open reading frame and extracted our genes of interest, the next goal of aim 2 was to translate each codon of the extracted nucleotide sequences into thier corresponding amino acids. To do this, we first created a dictionary of amino acids, which we could then apply to the nucleotide sequences using a while loop.

```{R}
###Make a directory of amino acids and thier names.
#Make a new list called amino_acid_list with the length of Codon_Map.
amino_acid_list <- vector(mode="list", length=length(Codon_Map))

#Use a regex to put all nucleotide codon sequences into it. 
Codons <- str_extract(Codon_Map,"[A-Z]{3}")

#Set the names of the amino acid list using Codons. 
names(amino_acid_list) <- Codons

#Then use a regex to extract the amino acid names and put it in a new variable.
amino_acids <- str_extract(Codon_Map,"[A-Za-z]{1,4}")

#Use a for loop to combine the nucleotide sequences with the amino acid names.
for (i in 1:length(amino_acid_list)){
  amino_acid_list[[i]] <- amino_acids[i]
}

### Create a new vector the length of *_ORF and use a for loop look at each sequnce.
#Set a variable to one and while that variable is less then the number of characters in each sequence of *_.ORF, replace each set of 3 nucleotides with the corresponding amino acid. Shfit the value of the nucleotide up 3 and repeat.
Control1_Protein = character(length(Control1_ORF))
for (sequence in 1:length(Control1_ORF)){
  nucleotide <- 1
    while (nucleotide < nchar(Control1_ORF[sequence])){
    Control1_Protein[sequence] = paste(Control1_Protein[sequence], amino_acid_list[substr(Control1_ORF[sequence], nucleotide,nucleotide+2)], sep="")
    nucleotide=nucleotide+3
  }
}

#Repeat for Control2, Obese1, and Obese2.
#Control2
Control2_Protein = character(length(Control2_ORF))
for (sequence in 1:length(Control2_ORF)){
  nucleotide <- 1
  while (nucleotide < nchar(Control2_ORF[sequence])){
    Control2_Protein[sequence] = paste(Control2_Protein[sequence], amino_acid_list[substr(Control2_ORF[sequence], nucleotide,nucleotide+2)], sep="")
    nucleotide=nucleotide+3
  }
}

#Obese1
Obese1_Protein = character(length(Obese1_ORF))
for (sequence in 1:length(Obese1_ORF)){
  nucleotide <- 1
  while (nucleotide < nchar(Obese1_ORF[sequence])){
    Obese1_Protein[sequence] = paste(Obese1_Protein[sequence], amino_acid_list[substr(Obese1_ORF[sequence], nucleotide,nucleotide+2)], sep="")
    nucleotide=nucleotide+3
  }
}

#Obese2
Obese2_Protein = character(length(Obese2_ORF))
for (sequence in 1:length(Obese2_ORF)){
  nucleotide <- 1
  while (nucleotide < nchar(Obese2_ORF[sequence])){
    Obese2_Protein[sequence] = paste(Obese2_Protein[sequence], amino_acid_list[substr(Obese2_ORF[sequence], nucleotide,nucleotide+2)], sep="")
    nucleotide=nucleotide+3
  }
}
```

The completed translations were exported as Fasta files.
```{R}
#Write each file out as a fasta file.
write.fasta(sequences = as.list(Control1_Protein), names = rep("Control1", times=length(Control1_Protein)),file.out = "Control1_Protein.fasta")

write.fasta(sequences = as.list(Control2_Protein), names = rep("Control2", times=length(Control2_Protein)),file.out = "Control2_Protein.fasta")

write.fasta(sequences = as.list(Obese1_Protein), names = rep("Obese1", times=length(Obese1_Protein)),file.out = "Obese1_Protein.fasta")

write.fasta(sequences = as.list(Obese2_Protein), names = rep("Obese2", times=length(Obese2_Protein)),file.out = "Obese2_Protein.fasta")
```

###Aim 3: Build a Hidden Markov model for each of the 6 protein files and search the "RNA seq" files for these proteins.

Aim 3 was broken down into three main steps:
1. Make a muscle alignment of each the 6 protein files.
2. Construct 6 HMM protein models from the resulting aligmnet files in HMMbuild.
3. Search all 4 of the translated "RNAseq files" for each of the 6 proteins using HMMsearch.

All three aims were completed in the Unix terminal with the following code:
```{Unix code2}
###Align reference sequence files using muscle and then build an HMM profile using hmmbuild.
#Set working directory
cd /Users/lou/Desktop/data-shell/BioInfo_GroupProject/Bioinformatics_GroupProject_BLS/Protein_FASTA_Files

###Align reference sequence files using muscle and a for loop.
for file in ./*.fasta
do
/Users/lou/Desktop/muscle3.8.31_i86darwin64 -in $file -out $file.align
done

###Build a profile HMM using alignment sequences and hmmbuild using a for loop.
for file in ./*.align
do
/Users/lou/Desktop/hmmer-3.1b2-macosx-intel/binaries/hmmbuild $file.hmm $file
done

### Please note that the 4 translated "RNAseq" files created in aim 2 were copied into the folder indicated for the set working directory prior to running the below mentioned code.

###Search all 4 translated “RNAseqfiles” for each of the 6 HMM protein models using hmmsearch.
for file in *_Protein.fasta
do 
for filename in *.hmm
do 
/Users/lou/Desktop/hmmer-3.1b2-macosx-intel/binaries/hmmsearch --tblout $file.$filename.Results.txt $filename $file 
done 
done
```

The output files were concatinated and edited to only include three columns: number of counts for each protein, the "RNAseq file" searched, and the transcript protein being searched. These were appended to a single file called All.Results.txt.

```{Unix code3}
#Cat all the results with a file name ending in Results.txt. Remove the lines beginning with #, and then print only columns 1 and 3.
#Use the unique funtion to count the number of hits for each file. Use awk one more time to remove space and append to a new file called All.Results.txt.
cat *Results.txt | grep -v '#' | awk '{print $1,$3}' | uniq -c | awk '{print $1,$2,$3}' >> All.Results.txt
```

###Aim 4: Graph the "expression levels" of each protein in each of the newly translated "RNAseq files."

Using All.Results.txt, we were then able to graph the "expression levels" of each protein in each of the "RNAseq files."

```{R}
##Back in R
setwd("~/Desktop/data-shell/BioInfo_GroupProject/Bioinformatics_GroupProject_BLS/Protein_FASTA_Files/")

#Load library
library(ggplot2)

#Read in fasta file, each line becomes an item in a vector
All_Results = read.table(file = "All.Results.txt", col.names = 1:3)

#Subset data by Transcript
Control1_Counts = subset(All_Results, X2 == "Control1", c(1-3))
Control2_Counts = subset(All_Results, X2 == "Control2", c(1-3))
Obese1_Counts = subset(All_Results, X2 == "Obese1", c(1-3))
Obese2_Counts = subset(All_Results, X2 == "Obese2", c(1-3))

#Plot the "expression levels" of each protein in the "RNAseq files."
#Control1
ggplot(data = Control1_Counts)+geom_bar(aes(x =as.factor(X3), y = X1), stat = "summary",fun.y = "mean", fill = "black", color = "black") +
  theme_classic() +xlab("Transcript") +ylab("Transcript Counts") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Control2
ggplot(data = Control2_Counts)+geom_bar(aes(x =as.factor(X3), y = X1), stat = "summary",fun.y = "mean", fill = "black", color = "black") +
  theme_classic() +xlab("Transcript") +ylab("Transcript Counts") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Obese1
ggplot(data = Obese1_Counts)+geom_bar(aes(x =as.factor(X3), y = X1), stat = "summary",fun.y = "mean", fill = "black", color = "black") +
  theme_classic() +xlab("Transcript") +ylab("Transcript Counts") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Obese2
ggplot(data = Obese2_Counts)+geom_bar(aes(x =as.factor(X3), y = X1), stat = "summary",fun.y = "mean", fill = "black", color = "black") +
  theme_classic() +xlab("Transcript") +ylab("Transcript Counts") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
##Further Exploration #1

###Aim: To evaluate the effect of choice among megablast, discontinous Megablast, and blastn algorithims on BLAST hit results  

The uniquetranscripts.fasta file was re-searched on the BLAST website. In order to make the comparisons easier, all BLAST hits were restricted to the mouse sequences. As per the instrucctions, the effect of running the search using megablast (default), discontinuous megablast, and blastn was evaluated on Transcripts 1, 6, and 8. The latter two algorithims are theoretically more lenient with their matching and supposedly allow sequences that would be too disimilar to the search sequence (the sequences from uniquetranscripts.fasta) to be reported as hits under the default megablast algorithim. The tables of BLAST hits which were compared are saved as excel tables in the repository. 
 
Looking at Transcript_1, right away it can be seen that megablast only reports 82 hits while the other two algorithims report 117 hits. Analyzing the patterns in the reported hits via E score sorted smallest to largest, the two alternative (discontinuous megablast and blastn) report extra matches which have higher (worse) E scores than the matches with the highest E scores reported by megablast. This correlates with the idea that these algorithims are more lenient than megablast. However, these algorithims also found some files with better E scores that megablast did not find. This likely indicates a difference in the way that these three algorithims interpret the differences between sequences and the way in which E scores are calculated.
  
Moving to Transcript_2, blastn and discontinuous megablast reported 44 matches while megablast reported only 29 matches, similar to the results with Transcript_1. Once again, the two alternative algorithims found more matches with low E scoes than what megablast found, yet the two alternative algorithims also found extra worse matches that megablast did not find.
  
Finally, for Transcript_3, megablast once more reported less total matches (68) than the alternative algorithims reported (both 146). However, while the alternative algorithims once again returned extra matches with higher E scores than the highest E scores returned with Megabalst, the alternative algorithims failed to find extra matches with lower E scores than those reported by Megablast. 
  
It is  important to note that for all of the transcripts investigated the alternative algorithims report the same E scores and the same number of matches, so they are likly reporting the same sequences as macthes.It is also important to recognize that while all three algorithims find a stretch of matches with E scores of 0, the extra "low E score" matches discussed here either refer to an extension of that string of 0 E score matches or lower E scores in the matches immediately following that string of 0 E score matches. The differences in these E scores could also arise from all of the algorithims finding the same good-match (low E score) sequences but that the different algorthims calculate the E scores differently (or input different values into the E score equation). Thus, while it is apparent that the alternative algorithims report extra sequences which are worse matches to the search sequence than the worst matches reported by megablast, it remains to be seen whether the extra low E scores reported by the alternative algorithims with 2 of the 3 transcripts studied (1 and 2) reflect actual extra good matches found by the alternative algorithims or simply slight differences in the way E scores are calculated among the algorithims.

Based on the counts of hmm hits for each transcript (our measure of RNA expression) in each "RNAseq file," most of our results align qualitatively to those reported in Kuhns & Pluznick 2017. Except for two genes discussed below. Please refer to our excel sheet titled "QualitativeComparision_expression.xlsx".
1. Slc7a12 in one of our groups (group1) has upregulation  where as in Kuhns & Pluznick 2017, it is downregulated.
2. Ptpn5 is downregulated in our group 2 where as in Kuhns & Pluznick 2017, it us upregulated.

